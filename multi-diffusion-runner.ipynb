{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3ed8b-9164-4f87-ae77-a2ecf8c9243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waifu Diffusion\n",
    "#!wget https://thisanimedoesnotexist.ai/downloads/wd-v1-2-full-ema.ckpt\n",
    "\n",
    "#Stable Diffusion\n",
    "#!wget https://r2-public-worker.drysys.workers.dev/sd-v1-4-full-ema.ckpt\n",
    "\n",
    "#Poke Diffusion\n",
    "!wget https://sd-finetune.vonk.workers.dev/pokediffusion_ckpts/pokediffusion_epoch_10_pruned.ckpt\n",
    "\n",
    "!git clone https://github.com/CompVis/stable-diffusion.git\n",
    "%cd stable-diffusion\n",
    "!wget https://raw.githubusercontent.com/justinpinkney/stable-diffusion/main/requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "!pip install --upgrade pytorch-lightning\n",
    "!apt-get update -y && apt-get install libgl1 -y && apt-get install libglib2.0-0 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b0f4e-8b77-452a-ab1e-2d1fb3822862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Restart your notebook here !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5e33af-a2db-43b2-9edf-e5223319047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/stable-diffusion\n"
     ]
    }
   ],
   "source": [
    "%cd stable-diffusion\n",
    "# Waifu Diffusion\n",
    "#ckpt_file = \"wd-v1-2-full-ema.ckpt\"\n",
    "\n",
    "#Stable Diffusion\n",
    "#ckpt_file = \"sd-v1-4-full-ema.ckpt\"\n",
    "\n",
    "#Poke Diffusion\n",
    "ckpt_file = \"pokediffusion_epoch_10_pruned.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7740d37e-93e3-485e-95a5-559b2c50f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import fire\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from torch import autocast\n",
    "from torchvision import transforms\n",
    "import requests\n",
    "\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n",
    "from ldm.models.diffusion.plms import PLMSSampler\n",
    "from ldm.util import instantiate_from_config\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b019ab3a-6bac-4125-a873-152d0ddf6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_config(config, ckpt, verbose=False):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    if \"global_step\" in pl_sd:\n",
    "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    if len(m) > 0 and verbose:\n",
    "        print(\"missing keys:\")\n",
    "        print(m)\n",
    "    if len(u) > 0 and verbose:\n",
    "        print(\"unexpected keys:\")\n",
    "        print(u)\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284b8b8-1230-4165-8238-bf5d53a8fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"configs/stable-diffusion/v1-inference.yaml\")\n",
    "model = load_model_from_config(config, f\"../{ckpt_file}\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "sampler = DDIMSampler(model)\n",
    "\n",
    "sample_path = \"outs\"\n",
    "os.makedirs(sample_path, exist_ok=True)\n",
    "\n",
    "start_code = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7328ca0f-0966-43c9-b2e7-1b2c06160184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae4b9f7-4ef1-4295-b104-32cbdfdaccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2a864-c484-4880-9883-3721b057491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1290026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.83it/s]\n",
      "Global seed set to 937160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.77it/s]\n",
      "Global seed set to 979059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.82it/s]\n",
      "Global seed set to 184899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.78it/s]\n",
      "Global seed set to 591307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.81it/s]\n",
      "Global seed set to 1527272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.80it/s]\n",
      "Global seed set to 871330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.80it/s]\n",
      "Global seed set to 1401714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "seeds = [random.randint(1, 2000000) for x in range(8)]\n",
    "for seed in seeds:\n",
    "    batch_size = 1\n",
    "\n",
    "    prompt = \"official art of a pokemon Abomasnow, Ice, Grass\"\n",
    "    scale = 7.5\n",
    "    C = 4\n",
    "    H = 512\n",
    "    W = 512\n",
    "    f = 8\n",
    "    data = [batch_size * [prompt]]\n",
    "\n",
    "    seed_everything(seed)\n",
    "\n",
    "    precision_scope = autocast\n",
    "    with torch.no_grad():\n",
    "        with precision_scope(\"cuda\"):\n",
    "            with model.ema_scope():\n",
    "                tic = time.time()\n",
    "                all_samples = list()\n",
    "                for n in range(1):\n",
    "                    for prompts in data:\n",
    "                        uc = None\n",
    "                        if scale != 1.0:\n",
    "                            uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
    "                        if isinstance(prompts, tuple):\n",
    "                            prompts = list(prompts)\n",
    "                        c = model.get_learned_conditioning(prompts)\n",
    "                        shape = [C, H // f, W // f]\n",
    "                        samples_ddim, _ = sampler.sample(S=50,\n",
    "                                                         conditioning=c,\n",
    "                                                         batch_size=1,\n",
    "                                                         shape=shape,\n",
    "                                                         verbose=False,\n",
    "                                                         unconditional_guidance_scale=scale,\n",
    "                                                         unconditional_conditioning=uc,\n",
    "                                                         eta=0.0,\n",
    "                                                         x_T=start_code)\n",
    "\n",
    "                        x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
    "                        x_samples_ddim = torch.clamp((x_samples_ddim + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "                        x_samples_ddim = x_samples_ddim.cpu().permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "                        x_checked_image_torch = torch.from_numpy(x_samples_ddim).permute(0, 3, 1, 2)\n",
    "\n",
    "                        for x_sample in x_checked_image_torch:\n",
    "                            x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
    "                            img = Image.fromarray(x_sample.astype(np.uint8))\n",
    "                            img.save(os.path.join(sample_path, f\"{prompt[:25]}_{seed}.png\"))\n",
    "\n",
    "                toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87576290-6108-46ce-a8ea-f570988ede05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
