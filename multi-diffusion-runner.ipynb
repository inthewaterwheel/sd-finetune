{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff3ed8b-9164-4f87-ae77-a2ecf8c9243c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-09-18 19:48:07--  https://sd-finetune.vonk.workers.dev/pokediffusion_ckpts/pokediffusion_epoch_10_pruned.ckpt\n",
      "Resolving sd-finetune.vonk.workers.dev (sd-finetune.vonk.workers.dev)... 172.67.194.133, 104.21.92.135, 2606:4700:3036::6815:5c87, ...\n",
      "Connecting to sd-finetune.vonk.workers.dev (sd-finetune.vonk.workers.dev)|172.67.194.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3852166575 (3.6G)\n",
      "Saving to: ‘pokediffusion_epoch_10_pruned.ckpt’\n",
      "\n",
      "pokediffusion_epoch 100%[===================>]   3.59G  38.8MB/s    in 98s     \n",
      "\n",
      "2022-09-18 19:49:47 (37.3 MB/s) - ‘pokediffusion_epoch_10_pruned.ckpt’ saved [3852166575/3852166575]\n",
      "\n",
      "Cloning into 'stable-diffusion'...\n",
      "remote: Enumerating objects: 313, done.\u001b[K\n",
      "remote: Total 313 (delta 0), reused 0 (delta 0), pack-reused 313\u001b[K\n",
      "Receiving objects: 100% (313/313), 42.62 MiB | 15.45 MiB/s, done.\n",
      "Resolving deltas: 100% (114/114), done.\n",
      "/workspace/stable-diffusion/stable-diffusion\n",
      "--2022-09-18 19:49:51--  https://raw.githubusercontent.com/justinpinkney/stable-diffusion/main/requirements.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 489 [text/plain]\n",
      "Saving to: ‘requirements.txt’\n",
      "\n",
      "requirements.txt    100%[===================>]     489  --.-KB/s    in 0s      \n",
      "\n",
      "2022-09-18 19:49:51 (25.2 MB/s) - ‘requirements.txt’ saved [489/489]\n",
      "\n",
      "Obtaining taming-transformers from git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers (from -r requirements.txt (line 20))\n",
      "  Cloning https://github.com/CompVis/taming-transformers.git (to revision master) to ./src/taming-transformers\n",
      "  Running command git clone -q https://github.com/CompVis/taming-transformers.git /workspace/stable-diffusion/stable-diffusion/src/taming-transformers\n",
      "  Resolved https://github.com/CompVis/taming-transformers.git to commit 24268930bf1dce879235a7fddd0b2355b84d7ea6\n",
      "Obtaining clip from git+https://github.com/openai/CLIP.git@main#egg=clip (from -r requirements.txt (line 21))\n",
      "  Cloning https://github.com/openai/CLIP.git (to revision main) to ./src/clip\n",
      "  Running command git clone -q https://github.com/openai/CLIP.git /workspace/stable-diffusion/stable-diffusion/src/clip\n",
      "  Resolved https://github.com/openai/CLIP.git to commit d50d76daa670286dd6cacf3bcd80b5e4823fc8e1\n",
      "Obtaining file:///workspace/stable-diffusion/stable-diffusion (from -r requirements.txt (line 22))\n",
      "Collecting albumentations==0.4.3\n",
      "  Downloading albumentations-0.4.3.tar.gz (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python==4.5.5.64\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.5 MB 7.0 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pudb==2019.2\n",
      "  Downloading pudb-2019.2.tar.gz (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio==2.9.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 31.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio-ffmpeg==0.4.2\n",
      "  Downloading imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 26.9 MB 19.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytorch-lightning==1.4.2\n",
      "  Downloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n",
      "\u001b[K     |████████████████████████████████| 916 kB 113.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting omegaconf==2.1.1\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[K     |████████████████████████████████| 74 kB 9.6 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting test-tube>=0.7.5\n",
      "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
      "Collecting streamlit>=0.73.1\n",
      "  Downloading streamlit-1.12.2-py2.py3-none-any.whl (9.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1 MB 33.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting einops==0.3.0\n",
      "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting torch-fidelity==0.3.0\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 67.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kornia==0.6\n",
      "  Downloading kornia-0.6.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001b[K     |████████████████████████████████| 367 kB 52.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting webdataset==0.2.5\n",
      "  Downloading webdataset-0.2.5-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 8.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torchmetrics==0.6.0\n",
      "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
      "\u001b[K     |████████████████████████████████| 329 kB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fire==0.4.0\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 16.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gradio==3.1.4\n",
      "  Downloading gradio-3.1.4-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 53.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting diffusers==0.3.0\n",
      "  Downloading diffusers-0.3.0-py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 52.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting datasets[vision]==2.4.0\n",
      "  Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "\u001b[K     |████████████████████████████████| 365 kB 34.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from albumentations==0.4.3->-r requirements.txt (line 1)) (1.21.5)\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.1 MB 17.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imgaug<0.2.7,>=0.2.5\n",
      "  Downloading imgaug-0.2.6.tar.gz (631 kB)\n",
      "\u001b[K     |████████████████████████████████| 631 kB 49.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from albumentations==0.4.3->-r requirements.txt (line 1)) (6.0)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 48.3 MB 50.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urwid>=1.1.1\n",
      "  Downloading urwid-2.1.2.tar.gz (634 kB)\n",
      "\u001b[K     |████████████████████████████████| 634 kB 57.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pygments>=1.0 in /opt/conda/lib/python3.7/site-packages (from pudb==2019.2->-r requirements.txt (line 3)) (2.11.2)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imageio==2.9.0->-r requirements.txt (line 4)) (9.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.4.2->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.4.2->-r requirements.txt (line 6)) (4.1.1)\n",
      "Collecting pyDeprecate==0.3.1\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting future>=0.17.1\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 49.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
      "  Downloading fsspec-2022.8.2-py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 59.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.4.2->-r requirements.txt (line 6)) (1.12.0)\n",
      "Collecting tensorboard>=2.2.0\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 3.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning==1.4.2->-r requirements.txt (line 6)) (4.63.0)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from torch-fidelity==0.3.0->-r requirements.txt (line 11)) (0.13.0)\n",
      "Collecting braceexpand\n",
      "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire==0.4.0->-r requirements.txt (line 16)) (1.16.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 56.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gradio==3.1.4->-r requirements.txt (line 17)) (2.27.1)\n",
      "Collecting h11<0.13,>=0.11\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting fastapi\n",
      "  Downloading fastapi-0.85.0-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 6.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 16.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.18.3-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 9.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting orjson\n",
      "  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 53.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.2 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycryptodome\n",
      "  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 27.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting analytics-python\n",
      "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Collecting markdown-it-py[linkify,plugins]\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 6.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic\n",
      "  Downloading pydantic-1.10.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8 MB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Jinja2 in /opt/conda/lib/python3.7/site-packages (from gradio==3.1.4->-r requirements.txt (line 17)) (3.1.2)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 6.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
      "Collecting paramiko\n",
      "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 40.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from diffusers==0.3.0->-r requirements.txt (line 18)) (3.6.0)\n",
      "Collecting huggingface-hub>=0.8.1\n",
      "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 58.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from diffusers==0.3.0->-r requirements.txt (line 18)) (4.12.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[K     |████████████████████████████████| 757 kB 67.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[K     |████████████████████████████████| 212 kB 47.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-9.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 35.3 MB 25.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 60.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click>=7.0\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 11.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting validators>=0.2\n",
      "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
      "\u001b[K     |████████████████████████████████| 235 kB 56.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 9)) (2.8.2)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.1.9-py3-none-manylinux2014_x86_64.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gitpython!=3.1.19\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "\u001b[K     |████████████████████████████████| 181 kB 56.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools>=4.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting blinker>=1.0.0\n",
      "  Downloading blinker-1.5-py2.py3-none-any.whl (12 kB)\n",
      "Collecting protobuf<4,>=3.12\n",
      "  Downloading protobuf-3.20.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 49.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tornado>=5.0 in /opt/conda/lib/python3.7/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 9)) (6.2)\n",
      "Collecting semver\n",
      "  Downloading semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.2.0-py3-none-any.whl (812 kB)\n",
      "\u001b[K     |████████████████████████████████| 812 kB 55.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pympler>=0.9\n",
      "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 82.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.8.0b3-py2.py3-none-any.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 57.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzlocal>=1.1\n",
      "  Downloading tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 31.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit>=0.73.1->-r requirements.txt (line 9)) (4.9.1)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 6.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from altair>=3.2.0->streamlit>=0.73.1->-r requirements.txt (line 9)) (0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.1.4->-r requirements.txt (line 17)) (22.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 5.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 60.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->gradio==3.1.4->-r requirements.txt (line 17)) (2.0.4)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting scikit-image>=0.11.0\n",
      "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.5 MB 19.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->diffusers==0.3.0->-r requirements.txt (line 18)) (3.8.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.73.1->-r requirements.txt (line 9)) (0.18.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.73.1->-r requirements.txt (line 9)) (1.3.10)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit>=0.73.1->-r requirements.txt (line 9)) (5.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning==1.4.2->-r requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->gradio==3.1.4->-r requirements.txt (line 17)) (2022.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2->gradio==3.1.4->-r requirements.txt (line 17)) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->gradio==3.1.4->-r requirements.txt (line 17)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gradio==3.1.4->-r requirements.txt (line 17)) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->gradio==3.1.4->-r requirements.txt (line 17)) (2022.6.15)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[K     |████████████████████████████████| 51 kB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.2\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 45.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "\u001b[K     |████████████████████████████████| 178 kB 54.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 51.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.11.0-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 57.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "\u001b[K     |████████████████████████████████| 232 kB 56.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[K     |████████████████████████████████| 93 kB 3.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 6)) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 60.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 6)) (61.2.0)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 83.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.49.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 51.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf<4,>=3.12\n",
      "  Downloading protobuf-3.19.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 58.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 60.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 9.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 63.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz-deprecation-shim\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting backports.zoneinfo\n",
      "  Downloading backports.zoneinfo-0.2.1-cp37-cp37m-manylinux1_x86_64.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from validators>=0.2->streamlit>=0.73.1->-r requirements.txt (line 9)) (5.1.1)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting backoff==1.10.0\n",
      "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting starlette==0.20.4\n",
      "  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 5.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.7/site-packages (from starlette==0.20.4->fastapi->gradio==3.1.4->-r requirements.txt (line 17)) (3.6.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.7/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi->gradio==3.1.4->-r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy->clip->-r requirements.txt (line 21)) (0.2.5)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore<0.16.0,>=0.15.0\n",
      "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 15.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting linkify-it-py~=1.0\n",
      "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
      "Collecting mdit-py-plugins\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 3.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.37.2-py3-none-any.whl (959 kB)\n",
      "\u001b[K     |████████████████████████████████| 959 kB 56.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 56.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pynacl>=1.0.1\n",
      "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
      "\u001b[K     |████████████████████████████████| 856 kB 63.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /opt/conda/lib/python3.7/site-packages (from paramiko->gradio==3.1.4->-r requirements.txt (line 17)) (37.0.1)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-4.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (594 kB)\n",
      "\u001b[K     |████████████████████████████████| 594 kB 45.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.7/site-packages (from cryptography>=2.5->paramiko->gradio==3.1.4->-r requirements.txt (line 17)) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio==3.1.4->-r requirements.txt (line 17)) (2.21)\n",
      "Collecting tzdata\n",
      "  Downloading tzdata-2022.2-py2.py3-none-any.whl (336 kB)\n",
      "\u001b[K     |████████████████████████████████| 336 kB 16.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: albumentations, pudb, fire, antlr4-python3-runtime, test-tube, future, imgaug, urwid, validators, ffmpy, python-multipart\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for albumentations: filename=albumentations-0.4.3-py3-none-any.whl size=60787 sha256=6b09ca092842659b180a0b8b8ed46db5251fce0fde054e733000a0e669c107c7\n",
      "  Stored in directory: /root/.cache/pip/wheels/9d/f4/ab/b45b873b6399eeb93386bee4f8bddb9ad0e2f54d34cde20861\n",
      "  Building wheel for pudb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pudb: filename=pudb-2019.2-py3-none-any.whl size=63238 sha256=ee38380743079e63cc6ec61911bb9c3d8a6b36d648c5efbad46b1adefa1ba38a\n",
      "  Stored in directory: /root/.cache/pip/wheels/5a/c7/00/df84da413844e8204a2a1aabcc75f10f50fc45f0a96fccb23e\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=47f9fcda9027d0f8ae3c0a53f5706a62aa585795b67cff6353d9c54007d77751\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=f9df6cfba0b23fd2158992bb0afbc79b9b974e6ec39c5a95a3b9331b34094242\n",
      "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
      "  Building wheel for test-tube (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25356 sha256=e56fc35d4564df2c0ad46a6df2811d8ba6547a88d87f4384d1a78f6a23b7f750\n",
      "  Stored in directory: /root/.cache/pip/wheels/1c/50/0d/15b3236957cc18a5c39ec4d4d4d21624f4d4a876756ec17064\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=ed92e8db14333154326fd17d592044c3f6a0e3070b0ca40261db30f12d6fe5ba\n",
      "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
      "  Building wheel for imgaug (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654021 sha256=eee7ce0f149ffe5fadb98132d6b5fda6a48289e8702a97460a298dc46e05987e\n",
      "  Stored in directory: /root/.cache/pip/wheels/89/72/98/3ebfdba1069a9a8eaaa7ae7265cfd67d63ef0197aaee2e5f9c\n",
      "  Building wheel for urwid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for urwid: filename=urwid-2.1.2-py3-none-any.whl size=235035 sha256=c0b8cee6a942effd2a3142813a0541edc3eaf298159783464b8ae47a08e7c113\n",
      "  Stored in directory: /root/.cache/pip/wheels/79/77/cf/cae9cf1cc3f1f777f9db531424bbd9e15aa38e4ca28dbe499e\n",
      "  Building wheel for validators (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=6bbaba973fd17b1da676a5dd6e1e98a6232cf7c397d4e85e1070960a5eae34f9\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=a7d20f56fea7d30a276eaf2d75b8e37c1d11adb3996feb9d34ea81da3e97ffb0\n",
      "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
      "  Building wheel for python-multipart (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=ae8e228eb7364e2274e8fa4c80eecb213aa3d45945c0b1252e8d3332fbcd1740\n",
      "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
      "Successfully built albumentations pudb fire antlr4-python3-runtime test-tube future imgaug urwid validators ffmpy python-multipart\n",
      "Installing collected packages: pyasn1, multidict, frozenlist, yarl, rsa, pyasn1-modules, oauthlib, mdurl, cachetools, asynctest, async-timeout, aiosignal, uc-micro-py, tzdata, tifffile, smmap, scipy, rfc3986, requests-oauthlib, PyWavelets, networkx, MarkupSafe, markdown-it-py, imageio, h11, google-auth, fsspec, dill, backports.zoneinfo, aiohttp, xxhash, werkzeug, toolz, tensorboard-plugin-wit, tensorboard-data-server, starlette, scikit-image, responses, pytz-deprecation-shim, pynacl, pydantic, pyarrow, protobuf, pandas, multiprocess, monotonic, mdit-py-plugins, markdown, linkify-it-py, kiwisolver, huggingface-hub, httpcore, grpcio, google-auth-oauthlib, gitdb, fonttools, cycler, commonmark, click, bcrypt, backoff, absl-py, watchdog, validators, uvicorn, urwid, tzlocal, torchmetrics, toml, tokenizers, termcolor, tensorboard, semver, rich, regex, python-multipart, pympler, pydub, pyDeprecate, pydeck, pycryptodome, paramiko, orjson, opencv-python-headless, matplotlib, imgaug, httpx, gitpython, future, ftfy, ffmpy, fastapi, datasets, braceexpand, blinker, antlr4-python3-runtime, analytics-python, altair, webdataset, transformers, torch-fidelity, test-tube, taming-transformers, streamlit, pytorch-lightning, pudb, opencv-python, omegaconf, latent-diffusion, kornia, imageio-ffmpeg, gradio, fire, einops, diffusers, clip, albumentations\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.0.1\n",
      "    Uninstalling MarkupSafe-2.0.1:\n",
      "      Successfully uninstalled MarkupSafe-2.0.1\n",
      "  Running setup.py develop for taming-transformers\n",
      "  Running setup.py develop for latent-diffusion\n",
      "  Running setup.py develop for clip\n",
      "Successfully installed MarkupSafe-2.1.1 PyWavelets-1.3.0 absl-py-1.2.0 aiohttp-3.8.1 aiosignal-1.2.0 albumentations-0.4.3 altair-4.2.0 analytics-python-1.4.0 antlr4-python3-runtime-4.8 async-timeout-4.0.2 asynctest-0.13.0 backoff-1.10.0 backports.zoneinfo-0.2.1 bcrypt-4.0.0 blinker-1.5 braceexpand-0.1.7 cachetools-5.2.0 click-8.1.3 clip-1.0 commonmark-0.9.1 cycler-0.11.0 datasets-2.4.0 diffusers-0.3.0 dill-0.3.5.1 einops-0.3.0 fastapi-0.85.0 ffmpy-0.3.0 fire-0.4.0 fonttools-4.37.2 frozenlist-1.3.1 fsspec-2022.8.2 ftfy-6.1.1 future-0.18.2 gitdb-4.0.9 gitpython-3.1.27 google-auth-2.11.0 google-auth-oauthlib-0.4.6 gradio-3.1.4 grpcio-1.49.0 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 huggingface-hub-0.9.1 imageio-2.9.0 imageio-ffmpeg-0.4.2 imgaug-0.2.6 kiwisolver-1.4.4 kornia-0.6.0 latent-diffusion-0.0.1 linkify-it-py-1.0.3 markdown-3.4.1 markdown-it-py-2.1.0 matplotlib-3.5.3 mdit-py-plugins-0.3.0 mdurl-0.1.2 monotonic-1.6 multidict-6.0.2 multiprocess-0.70.13 networkx-2.6.3 oauthlib-3.2.1 omegaconf-2.1.1 opencv-python-4.5.5.64 opencv-python-headless-4.6.0.66 orjson-3.8.0 pandas-1.3.5 paramiko-2.11.0 protobuf-3.19.5 pudb-2019.2 pyDeprecate-0.3.1 pyarrow-9.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycryptodome-3.15.0 pydantic-1.10.2 pydeck-0.8.0b3 pydub-0.25.1 pympler-1.0.1 pynacl-1.5.0 python-multipart-0.0.5 pytorch-lightning-1.4.2 pytz-deprecation-shim-0.1.0.post0 regex-2022.9.13 requests-oauthlib-1.3.1 responses-0.18.0 rfc3986-1.5.0 rich-12.5.1 rsa-4.9 scikit-image-0.19.3 scipy-1.7.3 semver-2.13.0 smmap-5.0.0 starlette-0.20.4 streamlit-1.12.2 taming-transformers-0.0.1 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 termcolor-2.0.1 test-tube-0.7.5 tifffile-2021.11.2 tokenizers-0.12.1 toml-0.10.2 toolz-0.12.0 torch-fidelity-0.3.0 torchmetrics-0.6.0 transformers-4.22.1 tzdata-2022.2 tzlocal-4.2 uc-micro-py-1.0.1 urwid-2.1.2 uvicorn-0.18.3 validators-0.20.0 watchdog-2.1.9 webdataset-0.2.5 werkzeug-2.2.2 xxhash-3.0.0 yarl-1.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.7/site-packages (1.4.2)\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.7.6-py3-none-any.whl (707 kB)\n",
      "\u001b[K     |████████████████████████████████| 707 kB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (4.63.0)\n",
      "Requirement already satisfied: pyDeprecate>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (0.3.1)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (2022.8.2)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
      "\u001b[K     |████████████████████████████████| 419 kB 63.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (6.0)\n",
      "Requirement already satisfied: torch>=1.9.* in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (1.12.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (4.1.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (2.10.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from pytorch-lightning) (1.21.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.8.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.27.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (0.13.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (22.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=17.0->pytorch-lightning) (3.0.9)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.2.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (61.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.37.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.4.6)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.49.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (3.19.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning) (0.6.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (4.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->pytorch-lightning) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.26.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.9.1->pytorch-lightning) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->pytorch-lightning) (2.1.1)\n",
      "Installing collected packages: torchmetrics, pytorch-lightning\n",
      "  Attempting uninstall: torchmetrics\n",
      "    Found existing installation: torchmetrics 0.6.0\n",
      "    Uninstalling torchmetrics-0.6.0:\n",
      "      Successfully uninstalled torchmetrics-0.6.0\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.4.2\n",
      "    Uninstalling pytorch-lightning-1.4.2:\n",
      "      Successfully uninstalled pytorch-lightning-1.4.2\n",
      "Successfully installed pytorch-lightning-1.7.6 torchmetrics-0.9.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Waifu Diffusion\n",
    "#!wget https://thisanimedoesnotexist.ai/downloads/wd-v1-2-full-ema.ckpt\n",
    "\n",
    "#Stable Diffusion\n",
    "#!wget https://r2-public-worker.drysys.workers.dev/sd-v1-4-full-ema.ckpt\n",
    "\n",
    "#Poke Diffusion\n",
    "!wget https://sd-finetune.vonk.workers.dev/pokediffusion_ckpts/pokediffusion_epoch_10_pruned.ckpt\n",
    "\n",
    "!git clone https://github.com/CompVis/stable-diffusion.git\n",
    "%cd stable-diffusion\n",
    "!wget https://raw.githubusercontent.com/justinpinkney/stable-diffusion/main/requirements.txt\n",
    "!pip install -r requirements.txt\n",
    "!pip install --upgrade pytorch-lightning\n",
    "!apt-get update -y && apt-get install libgl1 -y && apt-get install libglib2.0-0 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13b0f4e-8b77-452a-ab1e-2d1fb3822862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Restart your notebook here !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5e33af-a2db-43b2-9edf-e5223319047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/stable-diffusion\n"
     ]
    }
   ],
   "source": [
    "%cd stable-diffusion\n",
    "# Waifu Diffusion\n",
    "#ckpt_file = \"wd-v1-2-full-ema.ckpt\"\n",
    "\n",
    "#Stable Diffusion\n",
    "#ckpt_file = \"sd-v1-4-full-ema.ckpt\"\n",
    "\n",
    "#Poke Diffusion\n",
    "ckpt_file = \"pokediffusion_epoch_10_pruned.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7740d37e-93e3-485e-95a5-559b2c50f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import os\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import fire\n",
    "import numpy as np\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from torch import autocast\n",
    "from torchvision import transforms\n",
    "import requests\n",
    "\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n",
    "from ldm.models.diffusion.plms import PLMSSampler\n",
    "from ldm.util import instantiate_from_config\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b019ab3a-6bac-4125-a873-152d0ddf6c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_config(config, ckpt, verbose=False):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    if \"global_step\" in pl_sd:\n",
    "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    if len(m) > 0 and verbose:\n",
    "        print(\"missing keys:\")\n",
    "        print(m)\n",
    "    if len(u) > 0 and verbose:\n",
    "        print(\"unexpected keys:\")\n",
    "        print(u)\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e284b8b8-1230-4165-8238-bf5d53a8fd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ../pokediffusion_epoch_10_pruned.ckpt\n",
      "Global Step: 472080\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/DagnyT/hardnet/raw/master/pretrained/train_liberty_with_aug/checkpoint_liberty_with_aug.pth\" to /root/.cache/torch/hub/checkpoints/checkpoint_liberty_with_aug.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f791cba9dd454ba988d8fa6d0fcc9be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/5.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d037e8eb4a134501990a0b0dbda723eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaca417cf2f4a7380e7c755e0570ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec04ad8dbc344f9c99c58556aee70dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5815b95205d4133886db0f8e58e20ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/905 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23aa52f8967c46cdad45704a9a4a9119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ba88ab347c4c1ba146ebd68a31ecb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.6.layer_norm2.weight', 'text_projection.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'logit_scale', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.layer_norm2.weight', 'visual_projection.weight', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm2.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.embeddings.position_ids', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.15.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.5.mlp.fc1.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load(\"configs/stable-diffusion/v1-inference.yaml\")\n",
    "model = load_model_from_config(config, f\"../{ckpt_file}\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "sampler = DDIMSampler(model)\n",
    "\n",
    "sample_path = \"outs\"\n",
    "os.makedirs(sample_path, exist_ok=True)\n",
    "\n",
    "start_code = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7328ca0f-0966-43c9-b2e7-1b2c06160184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ae4b9f7-4ef1-4295-b104-32cbdfdaccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2a864-c484-4880-9883-3721b057491d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1290026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.83it/s]\n",
      "Global seed set to 937160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.77it/s]\n",
      "Global seed set to 979059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.82it/s]\n",
      "Global seed set to 184899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.78it/s]\n",
      "Global seed set to 591307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.81it/s]\n",
      "Global seed set to 1527272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.80it/s]\n",
      "Global seed set to 871330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.80it/s]\n",
      "Global seed set to 1401714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (1, 4, 64, 64), eta 0.0\n",
      "Running DDIM Sampling with 50 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|██████████| 50/50 [00:07<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "seeds = [random.randint(1, 2000000) for x in range(8)]\n",
    "for seed in seeds:\n",
    "    batch_size = 1\n",
    "\n",
    "    prompt = \"official art of a pokemon Abomasnow, Ice, Grass\"\n",
    "    scale = 7.5\n",
    "    C = 4\n",
    "    H = 512\n",
    "    W = 512\n",
    "    f = 8\n",
    "    data = [batch_size * [prompt]]\n",
    "\n",
    "    seed_everything(seed)\n",
    "\n",
    "    precision_scope = autocast\n",
    "    with torch.no_grad():\n",
    "        with precision_scope(\"cuda\"):\n",
    "            with model.ema_scope():\n",
    "                tic = time.time()\n",
    "                all_samples = list()\n",
    "                for n in range(1):\n",
    "                    for prompts in data:\n",
    "                        uc = None\n",
    "                        if scale != 1.0:\n",
    "                            uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
    "                        if isinstance(prompts, tuple):\n",
    "                            prompts = list(prompts)\n",
    "                        c = model.get_learned_conditioning(prompts)\n",
    "                        shape = [C, H // f, W // f]\n",
    "                        samples_ddim, _ = sampler.sample(S=50,\n",
    "                                                         conditioning=c,\n",
    "                                                         batch_size=1,\n",
    "                                                         shape=shape,\n",
    "                                                         verbose=False,\n",
    "                                                         unconditional_guidance_scale=scale,\n",
    "                                                         unconditional_conditioning=uc,\n",
    "                                                         eta=0.0,\n",
    "                                                         x_T=start_code)\n",
    "\n",
    "                        x_samples_ddim = model.decode_first_stage(samples_ddim)\n",
    "                        x_samples_ddim = torch.clamp((x_samples_ddim + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "                        x_samples_ddim = x_samples_ddim.cpu().permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "                        x_checked_image_torch = torch.from_numpy(x_samples_ddim).permute(0, 3, 1, 2)\n",
    "\n",
    "                        for x_sample in x_checked_image_torch:\n",
    "                            x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
    "                            img = Image.fromarray(x_sample.astype(np.uint8))\n",
    "                            img.save(os.path.join(sample_path, f\"{prompt[:25]}_{seed}.png\"))\n",
    "\n",
    "                toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87576290-6108-46ce-a8ea-f570988ede05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
